=================== SYSTEM ====================
System                Linux
Machine               x86_64
Platform              Linux-3.10.0-957.1.3.el7.x86_64-x86_64-with-redhat-7.3-Nitrogen
Platform version      #1 SMP Mon Nov 26 12:36:06 CST 2018
Processor             x86_64
Available CPUs        24

==================== MODEL ====================
Summary of MNISTNet

              name   class_name       input_shape      output_shape            weight_shapes   n_parameters    n_trainable                                                                settings
1   conv1           Conv2d       (-1, 1, 28, 28)   (-1, 10, 24, 24)  [(10, 1, 5, 5), (10,)]   tensor(260)    tensor(260)    {'stride': (1, 1), 'padding': (0, 0)}                                 
2   conv1_bn        BatchNorm2d  (-1, 10, 24, 24)  (-1, 10, 24, 24)  [(10,), (10,)]           tensor(20)     tensor(20)     {'momentum': 0.1, 'affine': True}                                     
3   conv1_pool      MaxPool2d    (-1, 10, 24, 24)  (-1, 10, 12, 12)  []                       0              0              {'kernel_size': (2, 2), 'stride': (2, 2), 'padding': 0, 'dilation': 1}
4   conv1_relu      ReLU         (-1, 10, 12, 12)  (-1, 10, 12, 12)  []                       0              0              -                                                                     
5   conv2           Conv2d       (-1, 10, 12, 12)  (-1, 20, 8, 8)    [(20, 10, 5, 5), (20,)]  tensor(5020)   tensor(5020)   {'stride': (1, 1), 'padding': (0, 0)}                                 
6   conv2_bn        BatchNorm2d  (-1, 20, 8, 8)    (-1, 20, 8, 8)    [(20,), (20,)]           tensor(40)     tensor(40)     {'momentum': 0.1, 'affine': True}                                     
7   conv2_pool      MaxPool2d    (-1, 20, 8, 8)    (-1, 20, 4, 4)    []                       0              0              {'kernel_size': (2, 2), 'stride': (2, 2), 'padding': 0, 'dilation': 1}
8   conv2_relu      ReLU         (-1, 20, 4, 4)    (-1, 20, 4, 4)    []                       0              0              -                                                                     
9   fc1             Linear       (-1, 320)         (-1, 50)          [(50, 320), (50,)]       tensor(16050)  tensor(16050)  -                                                                     
10  fc1_bn          BatchNorm1d  (-1, 50)          (-1, 50)          [(50,), (50,)]           tensor(100)    tensor(100)    {'momentum': 0.1, 'affine': True}                                     
11  fc1_relu        ReLU         (-1, 50)          (-1, 50)          []                       0              0              -                                                                     
12  fc2             Linear       (-1, 50)          (-1, 10)          [(10, 50), (10,)]        tensor(510)    tensor(510)    -                                                                     
13  fc2_logsoftmax  LogSoftmax   (-1, 10)          (-1, 10)          []                       0              0              -                                                                     

Parameters: 22000
Trainable parameters: 22000
Layers: 13
Trainable layers: 7

================== OPTIMIZER ==================
<class 'torch.optim.sgd.SGD'>
[{'dampening': 0,
  'initial_lr': 1.0,
  'label': 'model_params',
  'lr': 1.0,
  'momentum': 0.9,
  'nesterov': False,
  'params': [140284822684080,
             140284822686240,
             140284822686456,
             140284822686528,
             140284822687032,
             140284822687104,
             140284822687176,
             140284822687248,
             140284819894344,
             140284819894416,
             140284819894560,
             140284819894632,
             140284819895064,
             140284819895136],
  'weight_decay': 0.001}]

================= LR SCHEDULE =================
<class 'torch.optim.lr_scheduler.ExponentialLR'>
{'base_lrs': [1.0],
 'gamma': 1.0,
 'last_epoch': -1,
 'optimizer': SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 1.0
    label: model_params
    lr: 1.0
    momentum: 0.9
    nesterov: False
    weight_decay: 0.001
)}

================== ALGORITHM ==================
Algorithm             sNES
Environment           MNIST
Perturbations         100
Generations           100
Batch size            1000 
Safe mutation         None
Antithetic sampling   False
Adaptation sampling   False
Importance sampling   0.000000
Common random numbers False
Workers               24
Validation interval   25
Checkpoint interval   600s
Checkpoint directory  /zhome/ef/b/113856/Desktop/Master_Thesis/es-rl-master-thesis/es-rl/experiments/checkpoints/E001-MNIST_none/190107-183718.945766|sNES|MNIST|MNISTNet
CUDA                  False
Optimizing sigma      None
Sigma                 0.0500
Use MU baseline       False
Use SIGMA baseline    False
Use natural gradient  True
Do not rank transform False


